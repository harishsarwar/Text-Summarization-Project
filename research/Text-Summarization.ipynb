{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2ad59a-ce70-4140-8cf8-c40bb83f53d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d37981-0b33-44d7-9f46-1edefbf15051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e3fc16-8e83-4730-b5bd-4d8c558fa915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from accelerate) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Downloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.47.0\n",
      "Uninstalling transformers-4.47.0:\n",
      "  Successfully uninstalled transformers-4.47.0\n",
      "Found existing installation: accelerate 1.2.0\n",
      "Uninstalling accelerate-1.2.0:\n",
      "  Successfully uninstalled accelerate-1.2.0\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Using cached transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "Installing collected packages: accelerate, transformers\n",
      "Successfully installed accelerate-1.2.0 transformers-4.47.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate\n",
    "!pip uninstall -y transformers accelerate\n",
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69c2a4b-bbca-40cf-89b0-9c6b02b1c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy<2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399e16ba-8e6b-47a0-9c66-ed208b30c757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (0.26.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mdhar_hxm\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~reamlit (C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c484b84-0fab-4b1d-a02f-dfaa591d2872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mdhar_hxm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from evaluate import load  # Updated import\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac252687-3fce-450b-b21a-eed3ceee51f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d986013-c22f-45b8-9a83-fb3640e78325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# \"google/pegasus-cnn_dailymail\" hugging face model for text summarization.\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a932fb-bdc4-4e29-a4d7-e46c076f24d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted: ['.ipynb_checkpoints', 'samsum-test.csv', 'samsum-train.csv', 'samsum-validation.csv', 'samsum_dataset', 'summarizer-data.zip', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import requests  # library for making http request\n",
    "import zipfile   # library for working with zip files\n",
    "import os        # library for interacting with the operating system\n",
    "\n",
    "# Define the URL and output file paths\n",
    "url = \"https://github.com/entbappy/Branching-tutorial/raw/master/summarizer-data.zip\" # url of the zip file to download\n",
    "zip_path = \"summarizer-data.zip\" #local file path to save the downloaded zip file\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)        # send a GET request to download the file\n",
    "with open(zip_path, \"wb\") as file:  # open a file in write-binary mode\n",
    "    file.write(response.content)    # write the downloaded file content to disk\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:  # open the zip file in read mode\n",
    "    zip_ref.extractall(\".\")                      # extract all files to the current directory\n",
    "\n",
    "# Check extracted contents\n",
    "print(\"Files extracted:\", os.listdir(\".\"))  # printing a list of files in the current directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b4f4b22-85c2-4f85-9799-3294adbea796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum = load_from_disk(\"samsum_dataset\")\n",
    "dataset_samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ad23f9e-4dc5-4a44-8a85-e782fa1c1ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split lengths: [14732, 819, 818]\n",
      "Features: ['id', 'dialogue', 'summary']\n",
      "\n",
      "Dialogue\n",
      "Eric: MACHINE!\n",
      "Rob: That's so gr8!\n",
      "Eric: I know! And shows how Americans see Russian ;)\n",
      "Rob: And it's really funny!\n",
      "Eric: I know! I especially like the train part!\n",
      "Rob: Hahaha! No one talks to the machine like that!\n",
      "Eric: Is this his only stand-up?\n",
      "Rob: Idk. I'll check.\n",
      "Eric: Sure.\n",
      "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
      "Eric: Gr8! I'll watch them now!\n",
      "Rob: Me too!\n",
      "Eric: MACHINE!\n",
      "Rob: MACHINE!\n",
      "Eric: TTYL?\n",
      "Rob: Sure :)\n",
      "\n",
      "Summary\n",
      "Eric and Rob are going to watch a stand-up on youtube.\n"
     ]
    }
   ],
   "source": [
    "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n",
    "\n",
    "print(f\"split lengths: {split_lengths}\")\n",
    "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\nDialogue\")\n",
    "\n",
    "print(dataset_samsum[\"test\"][1][\"dialogue\"])\n",
    "\n",
    "print(\"\\nSummary\")\n",
    "\n",
    "print(dataset_samsum[\"test\"][1][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc59ff08-f501-4e14-acca-d8dd4a7ee9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text into the features based on vocaburary which proives model which i load in this project.\n",
    "def convert_examples_to_features(example_batch):\n",
    "  input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n",
    "\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n",
    "\n",
    "  return {\n",
    "      'input_ids' : input_encodings['input_ids'], # Responsible for text repersentation based on vocabury size\n",
    "      'attention_mask': input_encodings['attention_mask'], # responsible for indentify real data after padding\n",
    "      'labels': target_encodings['input_ids']  # take target values from the input_ids\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcd97598-7ef4-4ee5-93fb-2f1aff576901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6466eec9104490bcbc28faac6c22a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcbe65491e84095afd4d418f59104d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99646bbde5bd47c78523b994a4efb9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_samsum_pt =  dataset_samsum.map(convert_examples_to_features, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35e73f36-8999-4053-b0c0-e223efc4f6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 14732\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 more columns are add after converting text into the features repersentation.\n",
    "dataset_samsum_pt[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9840b0fd-9f76-4ee9-84df-5074c13e7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5bc9106-ff86-4a1b-b97a-a7797a667e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "trainer_args = TrainingArguments(\n",
    "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, logging_steps=10,\n",
    "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "    gradient_accumulation_steps=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aa3eb06-d9fe-4cad-ae8c-78d641f515ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdhar_hxm\\AppData\\Local\\Temp\\ipykernel_12680\\3860022235.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model_pegasus, args=trainer_args,\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
    "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_samsum_pt[\"test\"],\n",
    "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f7c34d9-a47d-4123-a7ba-a820387e061b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 55:37, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=51, training_loss=3.022708163541906, metrics={'train_runtime': 3393.1036, 'train_samples_per_second': 0.241, 'train_steps_per_second': 0.015, 'total_flos': 313450454089728.0, 'train_loss': 3.022708163541906, 'epoch': 0.9963369963369964})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d64cee9a-889f-4d7a-9689-7393723e44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_size_chunk(list_of_elements, batch_size):\n",
    "    \"\"\"Split the dataset into smaller batches that we can process\n",
    "    simultaneously. Yield successive batch-size chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i: i + batch_size]\n",
    "\n",
    "\n",
    "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
    "                                batch_size=16, device=None,\n",
    "                                column_text='article',\n",
    "                                column_summary='highlights'):\n",
    "    \"\"\"\n",
    "    Calculate metrics on the test dataset.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        raise ValueError(\"Device is not specified. Provide a device (e.g., 'cuda' or 'cpu').\")\n",
    "\n",
    "    article_batches = list(generate_batch_size_chunk(dataset[column_text], batch_size))\n",
    "    target_batches = list(generate_batch_size_chunk(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "        inputs = tokenizer(article_batch, max_length=1024, truncation=True,\n",
    "                           padding='max_length', return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                                    attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                                    length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        ''' Parameters for length penalty ensure that the model does not generate overly long sequences. '''\n",
    "        # Decode the generated text\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                              clean_up_tokenization_spaces=True)\n",
    "                             for s in summaries]\n",
    "\n",
    "        # Add predictions and references to the metric\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    # Compute and return the ROUGE score\n",
    "    score = metric.compute()\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e39f04cd-6b60-4a17-bd34-bfa4ad5d1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_name = [\"rouge1\",\"rouge2\",\"rougL\",\"rougeLsum\"]\n",
    "rouge_metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "160937b4-2320-4c16-80d9-9970075ba14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "000ff119-fc8c-478e-b6ba-339c7b0f0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate  # New library for metrics\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18b324d9-cf70-4a1a-aff6-6e5026e6a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_name = [\"rouge1\",\"rouge2\",\"rougeL\",\"rougeLsum\"]\n",
    "rouge_metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7470ba60-80e7-4bfa-a2a9-3ad39d4f559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:22<00:00, 40.52s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.263935</td>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.204846</td>\n",
       "      <td>0.206736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.263935  0.057306  0.204846   0.206736"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = calculate_metric_on_test_ds(\n",
    "    dataset_samsum['test'][0:10], rouge_metric, trainer.model, tokenizer, \n",
    "    batch_size=2, device=device, column_text=\"dialogue\", column_summary=\"summary\"\n",
    ")\n",
    "\n",
    "# Extract ROUGE scores\n",
    "rouge_dict = {rn: score[rn] for rn in rouge_name}\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa7b6af3-3db1-4222-ad50-45d0d1c07cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdhar_hxm\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model_pegasus.save_pretrained(\"pegasus-samsum-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50758e82-a1fb-4475-bbc3-5d5a50edc5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\spiece.model',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save tokenizer\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fca86ed4-63fe-4cfa-b788-2809303b653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14c2b2d9-64da-4c06-b06c-c80d7c601490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Reference Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
      "\n",
      "Model Summary:\n",
      "Amanda: Ask Larry Amanda: He called her last time we were at the park together .<n>Hannah: I'd rather you texted him .<n>Amanda: Just text him .\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\": 8, \"max_length\":128}\n",
    "\n",
    "smaple_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "\n",
    "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\", tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "\n",
    "##\n",
    "print(\"Dialogue\")\n",
    "print(smaple_text)\n",
    "\n",
    "print(\"\\nReference Summary:\")\n",
    "print(reference)\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(pipe(smaple_text, **gen_kwargs)[0][\"summary_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f3fdea-9a47-4e1b-909c-fb4e98dc5468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
